{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcc99643-ee3c-47a8-8d66-776f1439574f",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "To complete the following guide you will need to install the following packages:\n",
    "\n",
    "- openai\n",
    "- pandas\n",
    "- requests\n",
    "\n",
    "You will also need:\n",
    "\n",
    "- OpenAI account (https://platform.openai.com/)\n",
    "- OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37325ced-0bac-4114-ac6f-7675750be022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.2 is available.\n",
      "You should consider upgrading via the '/Users/scottkramer/.pyenv/versions/3.9.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai pandas requests --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c04f5690-a826-4f0f-9fb3-d69f1208a435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from openai import OpenAI\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70f0d69d-f8f0-4bb6-bca4-13da071e32a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below and set your OPENAI_API_KEY environment variable set to your account's key!\n",
    "# os.environ['OPENAI_API_KEY'] = 'XXX'\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3646919f-16fa-4927-86f0-b04d16e8496c",
   "metadata": {},
   "source": [
    "## Problem Definition: Insurance Support Ticket Classifier\n",
    "\n",
    "*Note: The problem definition, data, and labels used in this example were synthetically generated using an LLM.*\n",
    "\n",
    "In the insurance industry, customer support plays a crucial role in ensuring client satisfaction and retention. Insurance companies receive a high volume of support tickets daily, covering a wide range of topics such as billing, policy administration, claims assistance, and more. Manually categorizing these tickets can be time-consuming and inefficient, leading to longer response times and potentially impacting customer experience.\n",
    "\n",
    "### Task\n",
    "In last week's exercise, we performed prompt engineering to increase the accuracy of our predictions on the test.tsv dataset to 63.24%.\n",
    "\n",
    "This week, we will now fine-tune our first model to increase the accuracy even higher!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8116757-2105-4fd6-ad63-020f88400741",
   "metadata": {},
   "source": [
    "#### Labeled Data\n",
    "\n",
    "The data can be found in the week-2 `data` folder.\n",
    "\n",
    "We will use the following datasets:\n",
    "- `./data/train.tsv`\n",
    "- `./data/test.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13f39af4-94fc-4603-90c8-3646ff451edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_examples = pd.read_csv('data/train.tsv', sep='\\t')\n",
    "test_examples = pd.read_csv('data/test.tsv', sep='\\t')\n",
    "\n",
    "# In order to not leak information about the test labels into our prompts, the list of possible categories will be defined \n",
    "# based on the training labels.\n",
    "categories = sorted(training_examples['label'].unique().tolist())\n",
    "categories_str = '\\n'.join(categories)\n",
    "\n",
    "training_tickets = training_examples['text'].tolist()\n",
    "training_labels = training_examples['label'].tolist()\n",
    "\n",
    "test_tickets = test_examples['text'].tolist()\n",
    "test_labels = test_examples['label'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c578e1-5d37-4b55-8f0c-ea7f055991b4",
   "metadata": {},
   "source": [
    "### Dataset Curation\n",
    "\n",
    "We first must transform our dataset into the format expected by OpenAI, and then upload the dataset. The dataset must conform to the schema expected by the Chat Completions API.\n",
    "\n",
    "See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43987a02-e9f9-4b22-9729-7f410eed0770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(ticket):\n",
    "    return f\"\"\"classify a customer support ticket into one of the following categories:\n",
    "<categories>\n",
    "{categories_str}\n",
    "</categories>\n",
    "\n",
    "Here is the customer support ticket:    \n",
    "<ticket>{ticket}</ticket>\n",
    "\n",
    "Respond using this format:\n",
    "<category>The category label you chose goes here</category>\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6b5f572-c4b6-4f37-91e4-814115e47177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the training examples to the format expected by OpenaI.\n",
    "def training_examples_to_json(examples):\n",
    "    json_objs = list()\n",
    "    for idx, example in examples.iterrows():  \n",
    "        user_msg = create_prompt(example['text'])\n",
    "        asst_msg = f\"<category>{example['label']}</category>\"\n",
    "        msg = {\"messages\": [\n",
    "            {\"role\": \"user\", \"content\": user_msg}, \n",
    "            {\"role\": \"assistant\", \"content\": asst_msg}\n",
    "        ]}\n",
    "        json_objs.append(msg)\n",
    "    \n",
    "    return json_objs\n",
    "\n",
    "training_json = training_examples_to_json(training_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc7800f8-75b2-4fcd-b755-5db04f601ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-fuCR9aHq80i2e8XLTvVkvmsQ', bytes=52416, created_at=1724943702, filename='ticket-classification_training_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Writes the data to a file and then uploads it to OpenAI\n",
    "dataset_file_name = 'ticket-classification_training_data.jsonl'\n",
    "\n",
    "with open(dataset_file_name, 'w') as f:\n",
    "    for obj in training_json:\n",
    "        json.dump(obj, f)\n",
    "        f.write('\\n')\n",
    "\n",
    "client.files.create(\n",
    "  file=open(dataset_file_name, \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796eb433-8370-494a-82ce-df3054c0de87",
   "metadata": {},
   "source": [
    "### Fine-Tuning\n",
    "\n",
    "We will now fine-tune models using the OpenAI API. OpenAI supports creating fine-tuning jobs both via the fine-tuning UI or programmatically. The number of epochs, learning rate, and batch size can all be optimized manually for your use case. In this exercise, we will use the default parameters.\n",
    "\n",
    "See https://platform.openai.com/docs/guides/fine-tuning/create-a-fine-tuned-model for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0186ffee-554b-4587-a279-f9743a952859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-rRFzvpFyRis67jPmQOpo7ijA', created_at=1724943716, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-bFtmYNQfekSDNC4ezHI3dmrI', result_files=[], seed=1489947951, status='validating_files', trained_tokens=None, training_file='file-fuCR9aHq80i2e8XLTvVkvmsQ', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates a training job with the default hyperparameters\n",
    "client.fine_tuning.jobs.create(\n",
    "  training_file='file-fuCR9aHq80i2e8XLTvVkvmsQ', # the file ID that was returned when the training file was uploaded to the OpenAI API.\n",
    "  model='gpt-4o-mini-2024-07-18'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fa875c-d603-4afd-a869-efaf1b1fcbe5",
   "metadata": {},
   "source": [
    "### Evluate Results\n",
    "\n",
    "We will now deploy our models and evaluate the results. We will calculate the accuracy on two different models.\n",
    "\n",
    "- The base model gpt-4o-mini model without any fine-tuning.\n",
    "- Our fine-tuned model.\n",
    "\n",
    "In the example below, you'll see that fine-tuning improved accuracy on our test set from 69% to 94%!\n",
    "\n",
    "See https://platform.openai.com/docs/guides/fine-tuning/use-a-fine-tuned-model for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ad57cc5-d98c-43c5-a7d4-0567136a5994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses an LLM to predicted class labels for a list of support tickets\n",
    "def classify_tickets(tickets, model):\n",
    "    responses = list()\n",
    "\n",
    "    for ticket in tickets:\n",
    "        user_prompt = create_prompt(ticket)\n",
    "    \n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{ \"role\": \"user\", \"content\": user_prompt}],\n",
    "            temperature=0, # setting temperature to 0 for this use case, so that responses are as deterministic as possible\n",
    "            stop=[\"</category>\"],\n",
    "            max_tokens=2048,\n",
    "        )\n",
    "\n",
    "        response = response.choices[0].message.content.split(\"<category>\")[-1].strip()\n",
    "        responses.append(response)\n",
    "\n",
    "    return responses\n",
    "\n",
    "\n",
    "# Calculates the percent of predictions we classified correctly\n",
    "def evaluate_accuracy(predicted, actual):\n",
    "    num_correct = sum([predicted[i] == actual[i] for i in range(len(actual))])\n",
    "    return round(100 * num_correct / len(actual), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5e68e93-61f2-465d-8596-c32cdb896d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 70.59%\n",
      "Test Set Accuracy: 69.12%\n"
     ]
    }
   ],
   "source": [
    "# Determine how the base model without any fine-tuning performs\n",
    "model_id = 'gpt-4o-mini'\n",
    "\n",
    "training_responses = classify_tickets(\n",
    "    tickets=training_tickets, \n",
    "    model=model_id\n",
    ")\n",
    "accuracy = evaluate_accuracy(training_responses, training_labels)\n",
    "print(f\"Training Set Accuracy: {accuracy}%\")\n",
    "\n",
    "test_responses = classify_tickets(\n",
    "    tickets=test_tickets, \n",
    "    model=model_id\n",
    ")\n",
    "\n",
    "accuracy = evaluate_accuracy(test_responses, test_labels)\n",
    "print(f\"Test Set Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "556cc993-59ec-4f89-b33e-8bcd2d7d383f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 100.0%\n",
      "Test Set Accuracy: 94.12%\n"
     ]
    }
   ],
   "source": [
    "# Determine how the base model performs with the increases rank, epochs, and learning rate\n",
    "model_id = 'ft:gpt-4o-mini-2024-07-18:brainiac-labs::A1b3dY1n' # REPLACE THIS WITH THE OUTPUT MODEL ID IN THE OPENAI FINE-TUNING DASHBOARD\n",
    "\n",
    "training_responses = classify_tickets(\n",
    "    tickets=training_tickets, \n",
    "    model=model_id\n",
    ")\n",
    "accuracy = evaluate_accuracy(training_responses, training_labels)\n",
    "print(f\"Training Set Accuracy: {accuracy}%\")\n",
    "\n",
    "test_responses = classify_tickets(\n",
    "    tickets=test_tickets, \n",
    "    model=model_id\n",
    ")\n",
    "\n",
    "accuracy = evaluate_accuracy(test_responses, test_labels)\n",
    "print(f\"Test Set Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d159b1c0-c4dd-4a1f-b1e0-942c92a1dcbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
